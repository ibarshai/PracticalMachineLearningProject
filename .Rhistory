download.file("https://dl.dropboxusercontent.com/u/7710864/data/gaData.rda", destfile="C:/Users/18662/Desktop/Data Science/7 - Regression/gaData.rda")
load("C:/Users/18662/Desktop/Data Science/7 - Regression/gaData.rda")
gaData$julian = julian(gaData$date)
head(gaData)
plot(gaData$julian, gaData$visits)
plot(gaData$julian, gaData$visits)
plot(gaData$julian, gaData$visits, pch=19)
plot(gaData$julian, gaData$visits, pch=18)
plot(gaData$julian, gaData$visits, pch=17)
plot(gaData$julian, gaData$visits, pch=10)
plot(gaData$julian, gaData$visits, pch=1)
plot(gaData$julian, gaData$visits, pch=2)
plot(gaData$julian, gaData$visits, pch=3)
plot(gaData$julian, gaData$visits, pch=4)
plot(gaData$julian, gaData$visits, pch=5)
plot(gaData$julian, gaData$visits, pch=6)
plot(gaData$julian, gaData$visits, pch=8)
plot(gaData$julian, gaData$visits, pch=11)
plot(gaData$julian, gaData$visits, pch=15)
plot(gaData$julian, gaData$visits, pch=20)
plot(gaData$julian, gaData$visits, pch=19)
plot(gaData$julian, gaData$visits, pch=20)
plot(gaData$julian, gaData$visits, pch=20, col="blue")
plot(gaData$julian, gaData$visits, pch=20, col="red")
glm1<-glm(gaData$visits~gaData$julian,family="poisson")
lines(gaData$julian,glm1$fitted,col="blue",lwd=3)
symmary(glm1)
summary(glm1)
t = 1:10
t2 <- log(10) + t
offset(t2)
t
t2
?offset
?rhs
View(shuttle)
?rand
?sample
temp = sample(1:100, size=256)
temp = sample(1:100, 256)
temp = sample(1:100,1000,replace=T)
temp = sample(1:100, 256, replace=F)
temp = sample(1:100, 256, replace=T)
shuttle2 = cbind(shuttle, temp)
View(shuttle2)
plot(shuttle2$use, temp)
t = 1; glmt = glm(temp ~ use + offset(t), data=shuttle2, family = poisson)
t = rep(1,256)
glmt = glm(temp ~ use + offset(t), data=shuttle2, family = poisson)
summary(glmt$coef)
summary(glmt)
t2 = t + log(10)
glmt2 = glm(temp ~ use + offset(t2), data=shuttle2, family = poisson)
summary(glmt)$coef
summary(glmt2)$coef
log(10)
summary(glmt2)$coef[1,1]
summary(glmt)$coef[1,1] - summary(glmt2)$coef[1,1]
temp = sample(1:100, 256, replace=T)
shuttle2 = cbind(shuttle, temp)
t = rep(1,256)
glmt = glm(temp ~ use + offset(t), data=shuttle2, family = poisson)
t2 = t + log(10)
glmt2 = glm(temp ~ use + offset(t2), data=shuttle2, family = poisson)
cbind(summary(glmt)$coef[,1], summary(glmt2)$coef[,1])
summary(glmt)$coef[1,1] - summary(glmt2)$coef[1,1]
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
plot(x,y)
plot(x,y, pch=20)
x = -5:5
y = c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
knots = 0
splineTerms = sapply(knots,function(knot)(x>knot)*(x-knot))
xMat = cbind(1,x,splineTerms)
yhat = predict(lm(y~xMat-1))
plot(x,y, pch=20)
lines(x,yhat,col="red",lwd=2)
summary(lm(y~xMat-1))$coef
xmat
xMat
x = -5:5
y = c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
knots = 0
splineTerms = sapply(knots,function(knot)(x>knot)*(x-knot))
xMat = cbind(x,splineTerms)
yhat = predict(lm(y~xMat))
plot(x,y, pch=20)
lines(x,yhat,col="red",lwd=2)
summary(lm(y~xMat-1))$coef
x = -5:5
y = c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
knots = 0
splineTerms = sapply(knots,function(knot)(x>knot)*(x-knot))
xMat = cbind(x,splineTerms)
yhat = predict(lm(y~xMat))
plot(x,y, pch=20)
lines(x,yhat,col="red",lwd=2)
summary(lm(y~xMat-1))$coef
x = -5:5
y = c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
knots = 0
splineTerms = sapply(knots,function(knot)(x>knot)*(x-knot))
xMat = cbind(1, x,splineTerms)
yhat = predict(lm(y~xMat-1))
plot(x,y, pch=20)
lines(x,yhat,col="red",lwd=2)
summary(lm(y~xMat-1))$coef
abline(h=2)
abline(v=2)
abline(v=c(0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5)
)
abline(v=c(0,-0.5,-1,-1.5,-2,-2.5,-3,-3.5,-4,-4.5,-5))
1:3:0.5
?seq
abline(h=seq(0,5,0.5))
2.0372258-1.0241584
x = -5:5
y = c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
knots = 0
splineTerms = sapply(knots,function(knot)(x>knot)*(x-knot))
xMat = cbind(1, x,splineTerms)
yhat = predict(lm(y~xMat-1))
plot(x,y, pch=20)
lines(x,yhat,col="red",lwd=2)
summary(lm(y~xMat-1))$coef[3,1] - summary(lm(y~xMat-1))$coef[2,1]
x = -5:5
y = c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
knots = 0
splineTerms = sapply(knots,function(knot)(x>knot)*(x-knot))
xMat = cbind(1, x,splineTerms)
yhat = predict(lm(y~xMat-1))
plot(x,y, pch=20)
lines(x,yhat,col="red",lwd=2)
summary(lm(y~xMat-1))$coef[3,1] + summary(lm(y~xMat-1))$coef[2,1]
data(mtcars)
summary(lm(mpg ~ wt * am))
summary(lm(mpg ~ wt * am, data = mtcars))
summary(lm(mpg ~ am * wt, data = mtcars))
summary(lm(mpg ~ am + wt, data = mtcars))
summary(lm(mpg ~ am * wt * hp, data = mtcars))
summary(lm(mpg ~ am * wt + hp, data = mtcars))
summary(lm(mpg ~ am * wt + hp + wt*hp, data = mtcars))
install.packages("caret", lib="C:/Users/18662/Documents/R/win-library/3.0")
data = kernlab
data(kernlanb)
data(kernlab)
library(kernlab)
install.packages("kernlab", lib="C:/Users/18662/Documents/R/win-library/3.0")
data(kernlab)
data(spam)
library(kernlab)
data(spam)
names(spam)
library(caret)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling", lib="C:/Users/18662/Documents/R/win-library/3.0")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
library(ggplot2)
qplot(CompressiveStrength, data=training)
plot(training$CompressiveStrength)
qplot(th, CompressiveStrength, data=training)
qplot(seq_along(CompressiveStrength), CompressiveStrength, data=training)
qplot(seq_along(CompressiveStrength), CompressiveStrength, colour = Age, data=training)
qplot(seq_along(CompressiveStrength), CompressiveStrength, colour = Cement, data=training)
qplot(seq_along(CompressiveStrength), CompressiveStrength, colour = Superplasticizer, data=training)
summary(training$Age)
qplot(seq_along(CompressiveStrength), CompressiveStrength, colour = FlyAsh, data=training)
install.packages("Hmisc", lib="C:/Users/18662/Documents/R/win-library/3.0")
cutAge = cut2(training$Age, g=4)
library(Hmisc)
cutAge = cut2(training$Age, g=4)
qplot(seq_along(CompressiveStrength), CompressiveStrength, colour = cutAge, data=training)
View(training)
qplot(seq_along(CompressiveStrength), CompressiveStrength, colour = cut2(training$Cement, g=4), data=training)
qplot(seq_along(CompressiveStrength), CompressiveStrength, colour = cut2(training$BlastFurnaceSlag, g=4), data=training)
qplot(seq_along(CompressiveStrength), CompressiveStrength, colour = cut2(training[,BlastFurnaceSlag], g=4), data=training)
qplot(seq_along(CompressiveStrength), CompressiveStrength, colour = cut2(training[,2], g=4), data=training)
qplot(seq_along(CompressiveStrength), CompressiveStrength, colour = cut2(training[,3], g=4), data=training)
qplot(seq_along(CompressiveStrength), CompressiveStrength, colour = cut2(training[,4], g=4), data=training)
qplot(seq_along(CompressiveStrength), CompressiveStrength, colour = cut2(training[,5], g=4), data=training)
qplot(seq_along(CompressiveStrength), CompressiveStrength, colour = cut2(training[,6], g=4), data=training)
qplot(seq_along(CompressiveStrength), CompressiveStrength, colour = cut2(training[,7], g=4), data=training)
qplot(seq_along(CompressiveStrength), CompressiveStrength, colour = cut2(training[,8], g=4), data=training)
qplot(seq_along(CompressiveStrength), CompressiveStrength, colour = cut2(training[,9], g=4), data=training)
qplot(seq_along(CompressiveStrength), CompressiveStrength, color = cut2(training[,9], g=4), data=training)
qplot(seq_along(CompressiveStrength), CompressiveStrength, color = cut2(training[,9], g=4), data=training)
library(ggplot)
library(ggplot2)
library(caret)
qplot(seq_along(CompressiveStrength), CompressiveStrength, color = cut2(training[,9], g=4), data=training)
library(Hmisc)
qplot(seq_along(CompressiveStrength), CompressiveStrength, color = cut2(training[,9], g=4), data=training)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(Superplasticizer, data=training)
?preProc
?preProcess
summary(Superplasticizer)
summary(training$Superplasticizer)
log10(0)
summary(log10(training$Superplasticizer))
summary(log10(training$Superplasticizer+1))
qplot(log10(training$Superplasticizer+1))
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
trainingSub = training[,58:79]
names(trainingSub)
trainingSub = training[,58:69]
names(trainingSub)
?preProcess
preProc = preProcess(trainingSub, method="pca", thresh=0.8)
preProc[1]
preProc[2]
preProc[3]
preProc[4]
preProc[5]
preProc[6]
preProc[7]
preProc[8]
preProc[9]
trainPC = predict(preProc, trainingSub)
modelFitPC = train(training$diagnosis ~, method="glm", data=trainPC)
modelFitPC = train(training$diagnosis ~., method="glm", data=trainPC)
install.packages('e1071', dependencies=TRUE)
modelFitPC = train(training$diagnosis ~., method="glm", data=trainPC)
modelFit = train(training$diagnosis ~., method="glm", data=trainingSub)
confusionMatrix(modelFit)
confusionMatrix(modelFitPC)
modelFitPC = train(training$diagnosis ~., method="glm", data=trainPC)
modelFit   = train(training$diagnosis ~., method="glm", data=trainingSub)
testPC = predict(preProc, testingSub)
confusionMatrix(testing$diagnosis, predict(modelFit, testPC))
testingSub  = testing[,58:69]
testPC = predict(preProc, testingSub)
confusionMatrix(testing$diagnosis, predict(modelFit, testPC))
names(testPC)
names(testingSub)
predict(modelFit, testPC)
confusionMatrix(testing$diagnosis, predict(modelFit, testingSub))
confusionMatrix(testing$diagnosis, predict(modelFit, testing))
confusionMatrix(testing$diagnosis, predict(modelFitPC, testPC))
x=5
x=1
?Methods
?lm
?dgamma
?colSums
?show
?showMethods
?getMethod
?getClass
?Methods
?colSums
?show
library(caret)
library(AppliedPredictiveModeling)
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
names(training)
library(caret)
library(AppliedPredictiveModeling)
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
library(Hmisc)
names(training)
names(training$Superplasticizer)
unique(training$Superplasticizer)
plot(training$Superplasticizer)
unique(training$CompressiveStrength)
plot(training$CompressiveStrength)
head(training)
qplot(training$CompressiveStrength)
length(training$CompressiveStrength)
qplot(training$CompressiveStrength, 1:774)
qplot(training$CompressiveStrength, 1:length(training$CompressiveStrength))
qplot(1:length(training$CompressiveStrength), training$CompressiveStrength)
qp = qplot(training$CompressiveStrength, 1:length(training$CompressiveStrength))
qp + geom_smooth(method="lm", formula = y~x)
qp = qplot(training$CompressiveStrength, 1:length(training$CompressiveStrength), colour = training[,1])
qp + geom_smooth(method="lm", formula = y~x)
qp = qplot(training$CompressiveStrength, 1:length(training$CompressiveStrength), colour = training[,2])
qp + geom_smooth(method="lm", formula = y~x)
qp = qplot(training$CompressiveStrength, 1:length(training$CompressiveStrength), colour = training[,3])
qp + geom_smooth(method="lm", formula = y~x)
qp = qplot(training$CompressiveStrength, 1:length(training$CompressiveStrength), colour = training[,4])
qp + geom_smooth(method="lm", formula = y~x)
qp = qplot(training$CompressiveStrength, 1:length(training$CompressiveStrength), colour = training[,6])
qp + geom_smooth(method="lm", formula = y~x)
ncols(training)
names(training)
2+2
2
2+2
library(caret)
library(AppliedPredictiveModeling)
library(Hmisc)
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qp1 = qplot(training$CompressiveStrength, 1:length(training$CompressiveStrength), colour = training[,1])
qp2 = qplot(training$CompressiveStrength, 1:length(training$CompressiveStrength), colour = training[,2])
qp3 = qplot(training$CompressiveStrength, 1:length(training$CompressiveStrength), colour = training[,3])
qp4 = qplot(training$CompressiveStrength, 1:length(training$CompressiveStrength), colour = training[,4])
qp5 = qplot(training$CompressiveStrength, 1:length(training$CompressiveStrength), colour = training[,5])
qp6 = qplot(training$CompressiveStrength, 1:length(training$CompressiveStrength), colour = training[,6])
qp7 = qplot(training$CompressiveStrength, 1:length(training$CompressiveStrength), colour = training[,7])
qp8 = qplot(training$CompressiveStrength, 1:length(training$CompressiveStrength), colour = training[,8])
multiplot(qp1, qp2, qp3, qp4, qp5, qp6, qp7, qp8, cols=2)
library(gridExtra)
grid.arrange(qp1, qp2, qp3, qp4, qp5, qp6, qp7, qp8, ncol=2)
names(training)
qplot(training$Superplasticizer, geom="histogram")
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingSub = training[,58:69]
testingSub  = testing[,58:69]
preProc = preProcess(trainingSub, method="pca", thresh=0.8)
preProc$rotation
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
names(segmentationOriginal)
View(segmentationOriginal)
unique(segmentationOriginal$Case)
segmentationOriginal$Case=="Test"
testset = segmentationOriginal[segmentationOriginal$Case=="Test",]
trainset = segmentationOriginal[segmentationOriginal$Case=="Train",]
View(testset)
View(trainset)
segmentationOriginal$CART
names(segmentationOriginal)
View(segmentationOriginal)
set.seed(125)
modFit = train(Class ~ ., method="rpart", data=trainset)
?predict
print(modFit$finalModel)
install.packages("pgmm", lib="C:/Users/18662/Documents/R/win-library/3.0")
library(pgmm)
data(olive)
olive = olive[,-1]
head(olive)
unique(olive$Area)
modFitOlive = train(Area ~ ., method="rpart", data=olive)
View(olive)
qplot(olive$Area, olive$Palmitic)
qplot(olive$Area, olive$2)
qplot(olive$Area, olive[,2])
qplot(olive$Area, olive[,3])
qplot(olive$Area, olive[,4])
qplot(olive$Area, olive[,5])
qplot(olive$Area, olive[,6])
qplot(olive$Area, olive[,7])
qplot(olive$Area, olive[,8])
qplot(olive$Area, olive[,9])
print(modFitOlve$finalModel)
print(modFitOlive$finalModel)
newdata = as.data.frame(t(colMeans(olive)))
predict(modFitOlive, newdata = newdata)
library(ElemStatLearn)
install.packages("ElemStatLearn", lib="C:/Users/18662/Documents/R/win-library/3.0")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train4 = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train4,]
testSA = SAheart[-train4,]
names(trainSA)
set.seed(13234)
modFitSA = trainSA(chd ~ age+alcohol+obesity+tobacco+typea+ldl, method="glm", family="binomial", data=trainSA)
set.seed(13234)
modFitSA = train(chd ~ age+alcohol+obesity+tobacco+typea+ldl, method="glm", family="binomial", data=trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
missClass(trainSA, predict(modFitSA, newdata=trainSA))
TRUE * 1
FALSE * 1
summary(trainSA$cha)
summary(trainSA$chd)
head(trainSA)
unique(trainSA$chd)
modFitSAp = predict(modFitSA, newdata=trainSA)
missClass(trainSA$chd, predict(modFitSA, newdata=trainSA)$chd)
missClass(trainSA$chd, predict(modFitSA, newdata=trainSA))
missClass(testSA$chd, predict(modFitSA, newdata=trainSA))
missClass(testSA$chd, predict(modFitSA, newdata=testSA))
data(vowel.train)
data(vowel.test)
names(vowel.train)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
modFit5 = train(y ~ ., data = vowel.train, method = "rf", prox = TRUE)
varImp(modFit5)
# Load the CVS files from active directory
trainingdata = read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
testingdata  = read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
# Clean training set to remove all patchy data and convert factor variables to factor type
training = trainingdata[,-c(1:7)]
toBeRemoved = which(training[1,]=="" | is.na(training[1,]))
training = training[,-toBeRemoved]
training$classe = as.factor(training$classe)
# Clean testing set to make it look like training set
testing = testingdata[,-c(1:7)]
testing = testing[,-toBeRemoved]
testing = testing[,1:52]
# Clean up memory
rm(trainingdata); rm(testingdata); rm(toBeRemoved)
library(caret)
library(randomForest)
library(caret)
library(e1071)
#library(ggplot2)
library(Hmisc)
library(randomForest)
#library(gbm)
#library(gridExtra)
# Set working directory
setwd("C:/Users/18662/Desktop/Data Science/8 - Machine Learning/Assignments")
#=======================================================================================
#                      Load and Clean Up Training and Test Data                        #
#=======================================================================================
# Load the CVS files from active directory
trainingdata = read.csv("pml-training.csv")
testingdata  = read.csv("pml-testing.csv")
# Clean training set to remove all patchy data and convert factor variables to factor type
training = trainingdata[,-c(1:7)]
toBeRemoved = which(training[1,]=="" | is.na(training[1,]))
training = training[,-toBeRemoved]
training$classe = as.factor(training$classe)
# Clean testing set to make it look like training set
testing = testingdata[,-c(1:7)]
testing = testing[,-toBeRemoved]
testing = testing[,1:52]
# Clean up memory
rm(trainingdata); rm(testingdata); rm(toBeRemoved)
#=======================================================================================
#                                  Random Forest Model                                 #
#=======================================================================================
# Create a random forest model using all variables, time it
ptm <- proc.time()
set.seed(123)
modFitRF = randomForest(classe ~ ., data=training, ntree=50) #OOB estimate of  error rate: 0.29%
modelingtime = proc.time() - ptm
# user  system elapsed
#65.86    0.26   66.16
# Predict the classe variable in the test set
predictionRF = predict(modFitRF, testing)
errors = vector()
ratioTestRows = 0.1 #Select ratio of rows to treat as cross-validation test set
for(i in 1:10){
sampledRows = sample(nrow(training), round(nrow(training)*ratioTestRows), replace=FALSE)
cv.testing = training[sampledRows,]
cv.training = training[-sampledRows,]
modFitRFCV = randomForest(classe ~ ., data=cv.training, ntree=50)
predictionCV =predict(modFitRFCV, cv.testing)
cm = confusionMatrix(cv.testing$classe, predictionCV)
errors[i] = 1-cm$overall['Accuracy']
print(paste("Error for pass", i, ":", errors[i]))
rm(cv.training); rm(cv.testing); rm(modFitRFCV);
}
print(paste("Average error", ":", mean(errors)))
modFitRF
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(predictionRF)
predictionRF
